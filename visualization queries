Example Hive Queries
----------------------------------------------------
1. Analyze the Impact of Hours Studied on Exam Scores

SELECT hours_studied, AVG(exam_score) AS avg_exam_score
FROM students_performance_factors
GROUP BY hours_studied
ORDER BY hours_studied;
----------------------------------------------------

2. Correlation Between Sleep Hours and Exam Scores

SELECT sleep_hours, AVG(exam_score) AS avg_exam_score
FROM students_performance_factors
GROUP BY sleep_hours
ORDER BY sleep_hours;
----------------------------------------------------
3. Effect of Parental Education Level

SELECT parental_education_level, AVG(exam_score) AS avg_exam_score
FROM students_performance_factors
GROUP BY parental_education_level
ORDER BY avg_exam_score DESC;

----------------------------------------------------------
4. Identify Students with Learning Disabilities

SELECT learning_disabilities, AVG(exam_score) AS avg_exam_score
FROM students_performance_factors
GROUP BY learning_disabilities;
----------------------------------------------------------

5. Analyze the Role of Internet Access

SELECT internet_access, AVG(exam_score) AS avg_exam_score
FROM students_performance_factors
GROUP BY internet_access;
----------------------------------------------------------

6. Effect of Tutoring Sessions on Performance

SELECT tutoring_sessions, AVG(exam_score) AS avg_exam_score
FROM students_performance_factors
GROUP BY tutoring_sessions
ORDER BY tutoring_sessions;





Visualizing Data
To visualize the results:

Export the query results to a file in HDFS:
sql
Copy code

INSERT OVERWRITE DIRECTORY '/user/hadoop/studentspf1/output'
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ',' 
SELECT hours_studied, AVG(exam_score) AS avg_exam_score
FROM students_performance_factors
GROUP BY hours_studied;

--------------------------------------------------------------------
Advanced Analysis Using PySpark
If you prefer PySpark, load your dataset with the updated schema:

python
Copy code
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("StudentPerformance").getOrCreate()
df = spark.read.csv("/user/hadoop/studentspf1/studentsperformancefactors.csv", header=True, inferSchema=True)

# View the schema
df.printSchema()

# Example analysis: Impact of hours studied
df.groupBy("hours_studied").avg("exam_score").orderBy("hours_studied").show()

# Correlation analysis (optional)
df.corr("hours_studied", "exam_score")















